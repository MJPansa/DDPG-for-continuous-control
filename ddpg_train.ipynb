{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "from models import DDPGActor, DDPGCritic\n",
    "from utils import DDPGExperienceBuffer, EnvWrapper\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "PATH = 'Reacher_Linux/Reacher.x86_64'\n",
    "env = EnvWrapper(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = {'obs_space': env.observation_space,     # length of state vector\n",
    "        'action_space': env.action_space,       # number of actions\n",
    "        'n_hidden': 256,                        # number of hidden neurons per layer\n",
    "        'bs': 64,                               # number of samples per batch\n",
    "        'lr_actor': 1e-4,                       # learning rate for actor network\n",
    "        'lr_critic': 1e-3,                      # learning rate for critic network\n",
    "        'device': 'cuda:0',                     # device to use for computations\n",
    "        'gamma': .99,                           # discount factor\n",
    "        'noise_factor': 1.,                     # noise factor for action noise\n",
    "        'noise_decay': 0.999,                   # decay of noise factor applied after every update\n",
    "        'noise_minimum': 0.0001,                # minimum of noise factor\n",
    "        'buffer_size': 500_000,                 # buffer size/length of experience buffer\n",
    "        'episodes': 5000,                       # maximum of episodes to train for\n",
    "        'buffer_threshold': .10,                # buffer threshold before starting training\n",
    "        'train_every_n': 4,                     # train on one batch every n steps of the env\n",
    "        'model_update_every_n': 8,              # soft update of target models every n steps\n",
    "        'tau': 0.01,                            # value for soft updating the target networks tau*local+(1-tau)*target\n",
    "        'clip_grad': 1.,                        # clipping value for gradients\n",
    "        'exploration_steps': 50000              # number of random explorations steps before using network predictions\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the networks\n",
    "actor = DDPGActor(args['obs_space'], args['action_space'], args['n_hidden'], args['lr_actor'], args['device'])\n",
    "critic = DDPGCritic(args['obs_space'], args['action_space'], args['n_hidden'], args['lr_critic'], args['device'])\n",
    "actor_target = DDPGActor(args['obs_space'], args['action_space'], args['n_hidden'], args['lr_actor'], args['device'])\n",
    "critic_target = DDPGCritic(args['obs_space'], args['action_space'], args['n_hidden'], args['lr_critic'], args['device'])\n",
    "actor_target.load_state_dict(actor.state_dict())\n",
    "critic_target.load_state_dict(critic.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the experience buffer\n",
    "exp = DDPGExperienceBuffer(args['buffer_size'], args['bs'], args['buffer_threshold'], args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global stats to monitor\n",
    "step = 0\n",
    "mean_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "episode 0:\n",
      "rewards: 0.16\n",
      "actor loss: 0.000\n",
      "critic loss: 0.000\n",
      "noise factor: 1.0000\n",
      "buffer size: 20020\n",
      "\n",
      "episode 1:\n",
      "rewards: 0.17\n",
      "actor loss: 0.000\n",
      "critic loss: 0.000\n",
      "noise factor: 1.0000\n",
      "buffer size: 40040\n",
      "\n",
      "episode 2:\n",
      "rewards: 0.24\n",
      "actor loss: -17.735\n",
      "critic loss: 0.321\n",
      "noise factor: 0.8824\n",
      "buffer size: 60060\n",
      "\n",
      "episode 3:\n",
      "rewards: 0.17\n",
      "actor loss: -55.441\n",
      "critic loss: 0.168\n",
      "noise factor: 0.6865\n",
      "buffer size: 80080\n",
      "\n",
      "episode 4:\n",
      "rewards: 0.17\n",
      "actor loss: -72.729\n",
      "critic loss: 0.127\n",
      "noise factor: 0.5346\n",
      "buffer size: 100100\n",
      "\n",
      "episode 5:\n",
      "rewards: 0.12\n",
      "actor loss: -88.891\n",
      "critic loss: 0.139\n",
      "noise factor: 0.4163\n",
      "buffer size: 120120\n",
      "\n",
      "episode 6:\n",
      "rewards: 0.19\n",
      "actor loss: -101.284\n",
      "critic loss: 0.128\n",
      "noise factor: 0.3241\n",
      "buffer size: 140140\n",
      "\n",
      "episode 7:\n",
      "rewards: 0.16\n",
      "actor loss: -113.025\n",
      "critic loss: 0.131\n",
      "noise factor: 0.2522\n",
      "buffer size: 160160\n",
      "\n",
      "episode 8:\n",
      "rewards: 0.11\n",
      "actor loss: -121.496\n",
      "critic loss: 0.155\n",
      "noise factor: 0.1964\n",
      "buffer size: 180180\n",
      "\n",
      "episode 9:\n",
      "rewards: 0.13\n",
      "actor loss: -127.232\n",
      "critic loss: 0.179\n",
      "noise factor: 0.1529\n",
      "buffer size: 200200\n",
      "\n",
      "episode 10:\n",
      "rewards: 0.15\n",
      "actor loss: -132.791\n",
      "critic loss: 0.146\n",
      "noise factor: 0.1191\n",
      "buffer size: 220220\n",
      "\n",
      "episode 11:\n",
      "rewards: 0.21\n",
      "actor loss: -134.717\n",
      "critic loss: 0.064\n",
      "noise factor: 0.0926\n",
      "buffer size: 240240\n",
      "\n",
      "episode 12:\n",
      "rewards: 0.18\n",
      "actor loss: -134.615\n",
      "critic loss: 0.233\n",
      "noise factor: 0.0721\n",
      "buffer size: 260260\n",
      "\n",
      "episode 13:\n",
      "rewards: 0.23\n",
      "actor loss: -130.817\n",
      "critic loss: 0.144\n",
      "noise factor: 0.0562\n",
      "buffer size: 280280\n",
      "\n",
      "episode 14:\n",
      "rewards: 0.05\n",
      "actor loss: -125.923\n",
      "critic loss: 0.109\n",
      "noise factor: 0.0437\n",
      "buffer size: 300300\n",
      "\n",
      "episode 15:\n",
      "rewards: 0.15\n",
      "actor loss: -118.134\n",
      "critic loss: 0.090\n",
      "noise factor: 0.0340\n",
      "buffer size: 320320\n",
      "\n",
      "episode 16:\n",
      "rewards: 0.27\n",
      "actor loss: -107.697\n",
      "critic loss: 0.127\n",
      "noise factor: 0.0265\n",
      "buffer size: 340340\n",
      "\n",
      "episode 17:\n",
      "rewards: 0.22\n",
      "actor loss: -98.095\n",
      "critic loss: 0.084\n",
      "noise factor: 0.0206\n",
      "buffer size: 360360\n",
      "\n",
      "episode 18:\n",
      "rewards: 0.11\n",
      "actor loss: -111.244\n",
      "critic loss: 0.061\n",
      "noise factor: 0.0161\n",
      "buffer size: 380380\n",
      "\n",
      "episode 19:\n",
      "rewards: 0.26\n",
      "actor loss: -122.610\n",
      "critic loss: 0.140\n",
      "noise factor: 0.0125\n",
      "buffer size: 400400\n",
      "\n",
      "episode 20:\n",
      "rewards: 0.06\n",
      "actor loss: -128.953\n",
      "critic loss: 0.096\n",
      "noise factor: 0.0097\n",
      "buffer size: 420420\n",
      "\n",
      "episode 21:\n",
      "rewards: 0.09\n",
      "actor loss: -134.078\n",
      "critic loss: 0.109\n",
      "noise factor: 0.0076\n",
      "buffer size: 440440\n",
      "\n",
      "episode 22:\n",
      "rewards: 0.08\n",
      "actor loss: -139.742\n",
      "critic loss: 0.150\n",
      "noise factor: 0.0059\n",
      "buffer size: 460460\n",
      "\n",
      "episode 23:\n",
      "rewards: 0.15\n",
      "actor loss: -144.858\n",
      "critic loss: 0.118\n",
      "noise factor: 0.0046\n",
      "buffer size: 480480\n",
      "\n",
      "episode 24:\n",
      "rewards: 0.15\n",
      "actor loss: -147.707\n",
      "critic loss: 0.121\n",
      "noise factor: 0.0036\n",
      "buffer size: 500000\n",
      "\n",
      "episode 25:\n",
      "rewards: 0.09\n",
      "actor loss: -150.354\n",
      "critic loss: 0.141\n",
      "noise factor: 0.0028\n",
      "buffer size: 500000\n",
      "\n",
      "episode 26:\n",
      "rewards: 0.19\n",
      "actor loss: -152.151\n",
      "critic loss: 0.129\n",
      "noise factor: 0.0022\n",
      "buffer size: 500000\n",
      "\n",
      "episode 27:\n",
      "rewards: 0.05\n",
      "actor loss: -153.701\n",
      "critic loss: 0.109\n",
      "noise factor: 0.0017\n",
      "buffer size: 500000\n",
      "\n",
      "episode 28:\n",
      "rewards: 0.15\n",
      "actor loss: -153.561\n",
      "critic loss: 0.146\n",
      "noise factor: 0.0013\n",
      "buffer size: 500000\n",
      "\n",
      "episode 29:\n",
      "rewards: 0.06\n",
      "actor loss: -152.445\n",
      "critic loss: 0.160\n",
      "noise factor: 0.0010\n",
      "buffer size: 500000\n",
      "\n",
      "episode 30:\n",
      "rewards: 0.17\n",
      "actor loss: -148.944\n",
      "critic loss: 0.134\n",
      "noise factor: 0.0008\n",
      "buffer size: 500000\n",
      "\n",
      "episode 31:\n",
      "rewards: 0.21\n",
      "actor loss: -145.287\n",
      "critic loss: 0.082\n",
      "noise factor: 0.0006\n",
      "buffer size: 500000\n",
      "\n",
      "episode 32:\n",
      "rewards: 0.18\n",
      "actor loss: -139.541\n",
      "critic loss: 0.107\n",
      "noise factor: 0.0005\n",
      "buffer size: 500000\n",
      "\n",
      "episode 33:\n",
      "rewards: 0.27\n",
      "actor loss: -133.795\n",
      "critic loss: 0.107\n",
      "noise factor: 0.0004\n",
      "buffer size: 500000\n",
      "\n",
      "episode 34:\n",
      "rewards: 0.20\n",
      "actor loss: -126.859\n",
      "critic loss: 0.086\n",
      "noise factor: 0.0003\n",
      "buffer size: 500000\n",
      "\n",
      "episode 35:\n",
      "rewards: 0.14\n",
      "actor loss: -121.363\n",
      "critic loss: 0.070\n",
      "noise factor: 0.0002\n",
      "buffer size: 500000\n",
      "\n",
      "episode 36:\n",
      "rewards: 0.22\n",
      "actor loss: -120.025\n",
      "critic loss: 0.059\n",
      "noise factor: 0.0002\n",
      "buffer size: 500000\n",
      "\n",
      "episode 37:\n",
      "rewards: 0.18\n",
      "actor loss: -126.490\n",
      "critic loss: 0.069\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 38:\n",
      "rewards: 0.11\n",
      "actor loss: -128.798\n",
      "critic loss: 0.075\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 39:\n",
      "rewards: 0.14\n",
      "actor loss: -129.851\n",
      "critic loss: 0.077\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 40:\n",
      "rewards: 0.15\n",
      "actor loss: -129.472\n",
      "critic loss: 0.084\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 41:\n",
      "rewards: 0.13\n",
      "actor loss: -128.776\n",
      "critic loss: 0.079\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 42:\n",
      "rewards: 0.20\n",
      "actor loss: -126.362\n",
      "critic loss: 0.096\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 43:\n",
      "rewards: 0.17\n",
      "actor loss: -123.614\n",
      "critic loss: 0.062\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 44:\n",
      "rewards: 0.13\n",
      "actor loss: -118.850\n",
      "critic loss: 0.067\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 45:\n",
      "rewards: 0.16\n",
      "actor loss: -115.964\n",
      "critic loss: 0.086\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 46:\n",
      "rewards: 0.24\n",
      "actor loss: -118.145\n",
      "critic loss: 0.062\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 47:\n",
      "rewards: 0.14\n",
      "actor loss: -118.353\n",
      "critic loss: 0.062\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 48:\n",
      "rewards: 0.10\n",
      "actor loss: -116.981\n",
      "critic loss: 0.060\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 49:\n",
      "rewards: 0.18\n",
      "actor loss: -116.133\n",
      "critic loss: 0.087\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 50:\n",
      "rewards: 0.28\n",
      "actor loss: -115.791\n",
      "critic loss: 0.089\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 51:\n",
      "rewards: 0.13\n",
      "actor loss: -115.270\n",
      "critic loss: 0.056\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 52:\n",
      "rewards: 0.20\n",
      "actor loss: -113.860\n",
      "critic loss: 0.038\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 53:\n",
      "rewards: 0.66\n",
      "actor loss: -112.676\n",
      "critic loss: 0.052\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 54:\n",
      "rewards: 0.95\n",
      "actor loss: -111.389\n",
      "critic loss: 0.078\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 55:\n",
      "rewards: 0.89\n",
      "actor loss: -110.501\n",
      "critic loss: 0.050\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 56:\n",
      "rewards: 1.43\n",
      "actor loss: -108.549\n",
      "critic loss: 0.062\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 57:\n",
      "rewards: 1.60\n",
      "actor loss: -107.272\n",
      "critic loss: 0.035\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 58:\n",
      "rewards: 1.31\n",
      "actor loss: -106.288\n",
      "critic loss: 0.042\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 59:\n",
      "rewards: 0.80\n",
      "actor loss: -105.825\n",
      "critic loss: 0.044\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 60:\n",
      "rewards: 1.35\n",
      "actor loss: -104.201\n",
      "critic loss: 0.043\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 61:\n",
      "rewards: 1.23\n",
      "actor loss: -103.210\n",
      "critic loss: 0.042\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 62:\n",
      "rewards: 1.04\n",
      "actor loss: -102.043\n",
      "critic loss: 0.051\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 63:\n",
      "rewards: 1.53\n",
      "actor loss: -101.329\n",
      "critic loss: 0.046\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 64:\n",
      "rewards: 0.81\n",
      "actor loss: -99.790\n",
      "critic loss: 0.056\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 65:\n",
      "rewards: 0.93\n",
      "actor loss: -98.790\n",
      "critic loss: 0.043\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 66:\n",
      "rewards: 1.30\n",
      "actor loss: -97.724\n",
      "critic loss: 0.042\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 67:\n",
      "rewards: 1.86\n",
      "actor loss: -97.047\n",
      "critic loss: 0.060\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 68:\n",
      "rewards: 2.10\n",
      "actor loss: -95.659\n",
      "critic loss: 0.054\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 69:\n",
      "rewards: 1.73\n",
      "actor loss: -94.991\n",
      "critic loss: 0.042\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 70:\n",
      "rewards: 0.98\n",
      "actor loss: -94.198\n",
      "critic loss: 0.024\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 71:\n",
      "rewards: 2.02\n",
      "actor loss: -93.883\n",
      "critic loss: 0.051\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 72:\n",
      "rewards: 2.02\n",
      "actor loss: -92.885\n",
      "critic loss: 0.073\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 73:\n",
      "rewards: 1.99\n",
      "actor loss: -92.381\n",
      "critic loss: 0.042\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 74:\n",
      "rewards: 2.33\n",
      "actor loss: -91.887\n",
      "critic loss: 0.059\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 75:\n",
      "rewards: 1.60\n",
      "actor loss: -91.777\n",
      "critic loss: 0.059\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 76:\n",
      "rewards: 1.43\n",
      "actor loss: -90.893\n",
      "critic loss: 0.061\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 77:\n",
      "rewards: 2.16\n",
      "actor loss: -90.759\n",
      "critic loss: 0.046\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 78:\n",
      "rewards: 2.40\n",
      "actor loss: -90.693\n",
      "critic loss: 0.065\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 79:\n",
      "rewards: 2.11\n",
      "actor loss: -90.808\n",
      "critic loss: 0.050\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 80:\n",
      "rewards: 2.90\n",
      "actor loss: -90.158\n",
      "critic loss: 0.048\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 81:\n",
      "rewards: 3.66\n",
      "actor loss: -90.162\n",
      "critic loss: 0.066\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 82:\n",
      "rewards: 3.21\n",
      "actor loss: -89.770\n",
      "critic loss: 0.080\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 83:\n",
      "rewards: 3.85\n",
      "actor loss: -90.361\n",
      "critic loss: 0.062\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 84:\n",
      "rewards: 3.91\n",
      "actor loss: -90.281\n",
      "critic loss: 0.081\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 85:\n",
      "rewards: 4.32\n",
      "actor loss: -90.590\n",
      "critic loss: 0.109\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 86:\n",
      "rewards: 3.71\n",
      "actor loss: -90.944\n",
      "critic loss: 0.089\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 87:\n",
      "rewards: 4.96\n",
      "actor loss: -91.801\n",
      "critic loss: 0.102\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 88:\n",
      "rewards: 5.56\n",
      "actor loss: -91.816\n",
      "critic loss: 0.086\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 89:\n",
      "rewards: 5.06\n",
      "actor loss: -92.584\n",
      "critic loss: 0.112\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 90:\n",
      "rewards: 5.36\n",
      "actor loss: -93.691\n",
      "critic loss: 0.133\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 91:\n",
      "rewards: 6.53\n",
      "actor loss: -94.717\n",
      "critic loss: 0.134\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 92:\n",
      "rewards: 6.11\n",
      "actor loss: -95.358\n",
      "critic loss: 0.145\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 93:\n",
      "rewards: 7.19\n",
      "actor loss: -96.801\n",
      "critic loss: 0.146\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 94:\n",
      "rewards: 7.53\n",
      "actor loss: -98.466\n",
      "critic loss: 0.154\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 95:\n",
      "rewards: 6.81\n",
      "actor loss: -100.492\n",
      "critic loss: 0.169\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 96:\n",
      "rewards: 7.95\n",
      "actor loss: -101.672\n",
      "critic loss: 0.173\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 97:\n",
      "rewards: 8.56\n",
      "actor loss: -103.411\n",
      "critic loss: 0.214\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 98:\n",
      "rewards: 7.56\n",
      "actor loss: -105.528\n",
      "critic loss: 0.235\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 99:\n",
      "rewards: 7.65\n",
      "actor loss: -107.039\n",
      "critic loss: 0.234\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 100:\n",
      "rewards: 10.26\n",
      "actor loss: -108.897\n",
      "critic loss: 0.216\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 101:\n",
      "rewards: 9.91\n",
      "actor loss: -111.526\n",
      "critic loss: 0.229\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 102:\n",
      "rewards: 10.85\n",
      "actor loss: -114.303\n",
      "critic loss: 0.231\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 103:\n",
      "rewards: 10.00\n",
      "actor loss: -117.543\n",
      "critic loss: 0.283\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 104:\n",
      "rewards: 10.10\n",
      "actor loss: -120.265\n",
      "critic loss: 0.261\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 105:\n",
      "rewards: 10.62\n",
      "actor loss: -123.607\n",
      "critic loss: 0.297\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 106:\n",
      "rewards: 11.23\n",
      "actor loss: -125.844\n",
      "critic loss: 0.277\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 107:\n",
      "rewards: 9.78\n",
      "actor loss: -130.269\n",
      "critic loss: 0.298\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 108:\n",
      "rewards: 10.08\n",
      "actor loss: -132.787\n",
      "critic loss: 0.300\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 109:\n",
      "rewards: 12.70\n",
      "actor loss: -135.969\n",
      "critic loss: 0.347\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 110:\n",
      "rewards: 9.92\n",
      "actor loss: -139.497\n",
      "critic loss: 0.348\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 111:\n",
      "rewards: 8.91\n",
      "actor loss: -142.879\n",
      "critic loss: 0.383\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 112:\n",
      "rewards: 9.03\n",
      "actor loss: -145.095\n",
      "critic loss: 0.334\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 113:\n",
      "rewards: 10.47\n",
      "actor loss: -148.144\n",
      "critic loss: 0.423\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 114:\n",
      "rewards: 8.71\n",
      "actor loss: -150.837\n",
      "critic loss: 0.309\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 115:\n",
      "rewards: 10.21\n",
      "actor loss: -155.685\n",
      "critic loss: 0.404\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 116:\n",
      "rewards: 8.71\n",
      "actor loss: -159.489\n",
      "critic loss: 0.414\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 117:\n",
      "rewards: 13.34\n",
      "actor loss: -161.196\n",
      "critic loss: 0.398\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 118:\n",
      "rewards: 10.48\n",
      "actor loss: -164.155\n",
      "critic loss: 0.368\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 119:\n",
      "rewards: 10.79\n",
      "actor loss: -167.981\n",
      "critic loss: 0.570\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 120:\n",
      "rewards: 9.77\n",
      "actor loss: -169.676\n",
      "critic loss: 0.463\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 121:\n",
      "rewards: 10.44\n",
      "actor loss: -172.468\n",
      "critic loss: 0.506\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 122:\n",
      "rewards: 12.84\n",
      "actor loss: -174.730\n",
      "critic loss: 0.376\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 123:\n",
      "rewards: 13.77\n",
      "actor loss: -179.138\n",
      "critic loss: 0.401\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 124:\n",
      "rewards: 13.24\n",
      "actor loss: -182.072\n",
      "critic loss: 0.567\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 125:\n",
      "rewards: 13.74\n",
      "actor loss: -186.048\n",
      "critic loss: 0.482\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 126:\n",
      "rewards: 13.67\n",
      "actor loss: -187.419\n",
      "critic loss: 0.508\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 127:\n",
      "rewards: 12.18\n",
      "actor loss: -190.498\n",
      "critic loss: 0.496\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 128:\n",
      "rewards: 11.54\n",
      "actor loss: -191.858\n",
      "critic loss: 0.513\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 129:\n",
      "rewards: 13.26\n",
      "actor loss: -196.386\n",
      "critic loss: 0.575\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 130:\n",
      "rewards: 12.03\n",
      "actor loss: -197.840\n",
      "critic loss: 0.459\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 131:\n",
      "rewards: 14.07\n",
      "actor loss: -203.273\n",
      "critic loss: 0.511\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 132:\n",
      "rewards: 11.04\n",
      "actor loss: -206.051\n",
      "critic loss: 0.522\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 133:\n",
      "rewards: 12.78\n",
      "actor loss: -208.888\n",
      "critic loss: 0.684\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 134:\n",
      "rewards: 12.65\n",
      "actor loss: -212.626\n",
      "critic loss: 0.555\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 135:\n",
      "rewards: 10.34\n",
      "actor loss: -215.870\n",
      "critic loss: 0.895\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 136:\n",
      "rewards: 12.33\n",
      "actor loss: -217.651\n",
      "critic loss: 0.558\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 137:\n",
      "rewards: 13.94\n",
      "actor loss: -221.661\n",
      "critic loss: 0.856\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 138:\n",
      "rewards: 14.62\n",
      "actor loss: -224.597\n",
      "critic loss: 0.758\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 139:\n",
      "rewards: 14.74\n",
      "actor loss: -230.370\n",
      "critic loss: 0.726\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 140:\n",
      "rewards: 12.56\n",
      "actor loss: -233.988\n",
      "critic loss: 0.694\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 141:\n",
      "rewards: 12.50\n",
      "actor loss: -236.028\n",
      "critic loss: 0.677\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 142:\n",
      "rewards: 14.06\n",
      "actor loss: -238.604\n",
      "critic loss: 0.763\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 143:\n",
      "rewards: 12.00\n",
      "actor loss: -243.097\n",
      "critic loss: 0.752\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 144:\n",
      "rewards: 16.33\n",
      "actor loss: -244.416\n",
      "critic loss: 0.794\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 145:\n",
      "rewards: 15.51\n",
      "actor loss: -248.425\n",
      "critic loss: 0.846\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 146:\n",
      "rewards: 11.67\n",
      "actor loss: -251.077\n",
      "critic loss: 0.911\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 147:\n",
      "rewards: 13.43\n",
      "actor loss: -253.909\n",
      "critic loss: 0.875\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 148:\n",
      "rewards: 14.53\n",
      "actor loss: -257.118\n",
      "critic loss: 0.691\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 149:\n",
      "rewards: 13.67\n",
      "actor loss: -260.135\n",
      "critic loss: 0.849\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 150:\n",
      "rewards: 15.55\n",
      "actor loss: -263.483\n",
      "critic loss: 0.972\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 151:\n",
      "rewards: 16.16\n",
      "actor loss: -266.924\n",
      "critic loss: 0.939\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 152:\n",
      "rewards: 15.41\n",
      "actor loss: -269.372\n",
      "critic loss: 1.092\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 153:\n",
      "rewards: 16.35\n",
      "actor loss: -271.789\n",
      "critic loss: 0.790\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 154:\n",
      "rewards: 16.82\n",
      "actor loss: -275.118\n",
      "critic loss: 0.973\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 155:\n",
      "rewards: 16.70\n",
      "actor loss: -280.530\n",
      "critic loss: 0.892\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 156:\n",
      "rewards: 15.56\n",
      "actor loss: -280.896\n",
      "critic loss: 0.870\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 157:\n",
      "rewards: 18.46\n",
      "actor loss: -286.165\n",
      "critic loss: 0.963\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 158:\n",
      "rewards: 19.01\n",
      "actor loss: -289.634\n",
      "critic loss: 0.860\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 159:\n",
      "rewards: 16.33\n",
      "actor loss: -293.167\n",
      "critic loss: 0.890\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 160:\n",
      "rewards: 16.14\n",
      "actor loss: -296.530\n",
      "critic loss: 1.095\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 161:\n",
      "rewards: 17.32\n",
      "actor loss: -297.344\n",
      "critic loss: 0.908\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 162:\n",
      "rewards: 14.92\n",
      "actor loss: -300.778\n",
      "critic loss: 0.881\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 163:\n",
      "rewards: 18.17\n",
      "actor loss: -305.532\n",
      "critic loss: 1.016\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 164:\n",
      "rewards: 25.34\n",
      "actor loss: -308.081\n",
      "critic loss: 0.838\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 165:\n",
      "rewards: 16.37\n",
      "actor loss: -312.495\n",
      "critic loss: 1.021\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 166:\n",
      "rewards: 17.24\n",
      "actor loss: -316.826\n",
      "critic loss: 1.139\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 167:\n",
      "rewards: 19.59\n",
      "actor loss: -320.339\n",
      "critic loss: 1.438\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 168:\n",
      "rewards: 15.97\n",
      "actor loss: -323.752\n",
      "critic loss: 1.180\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 169:\n",
      "rewards: 20.07\n",
      "actor loss: -329.647\n",
      "critic loss: 0.907\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 170:\n",
      "rewards: 20.92\n",
      "actor loss: -330.179\n",
      "critic loss: 1.241\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 171:\n",
      "rewards: 20.74\n",
      "actor loss: -337.147\n",
      "critic loss: 0.923\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 172:\n",
      "rewards: 22.88\n",
      "actor loss: -340.473\n",
      "critic loss: 1.080\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 173:\n",
      "rewards: 23.21\n",
      "actor loss: -345.401\n",
      "critic loss: 0.882\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 174:\n",
      "rewards: 21.91\n",
      "actor loss: -350.249\n",
      "critic loss: 0.981\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 175:\n",
      "rewards: 23.12\n",
      "actor loss: -358.068\n",
      "critic loss: 1.077\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 176:\n",
      "rewards: 22.78\n",
      "actor loss: -359.785\n",
      "critic loss: 1.221\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 177:\n",
      "rewards: 24.27\n",
      "actor loss: -366.875\n",
      "critic loss: 1.053\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 178:\n",
      "rewards: 26.58\n",
      "actor loss: -373.592\n",
      "critic loss: 1.214\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 179:\n",
      "rewards: 23.07\n",
      "actor loss: -381.793\n",
      "critic loss: 1.161\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 180:\n",
      "rewards: 26.18\n",
      "actor loss: -384.311\n",
      "critic loss: 1.166\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 181:\n",
      "rewards: 25.27\n",
      "actor loss: -394.256\n",
      "critic loss: 0.957\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 182:\n",
      "rewards: 23.28\n",
      "actor loss: -401.012\n",
      "critic loss: 1.432\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 183:\n",
      "rewards: 25.09\n",
      "actor loss: -408.285\n",
      "critic loss: 1.440\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 184:\n",
      "rewards: 26.68\n",
      "actor loss: -411.194\n",
      "critic loss: 1.127\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 185:\n",
      "rewards: 24.89\n",
      "actor loss: -418.344\n",
      "critic loss: 1.282\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 186:\n",
      "rewards: 27.13\n",
      "actor loss: -425.654\n",
      "critic loss: 1.403\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 187:\n",
      "rewards: 29.38\n",
      "actor loss: -434.590\n",
      "critic loss: 1.169\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 188:\n",
      "rewards: 30.53\n",
      "actor loss: -440.797\n",
      "critic loss: 1.682\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 189:\n",
      "rewards: 27.88\n",
      "actor loss: -444.356\n",
      "critic loss: 1.607\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 190:\n",
      "rewards: 27.61\n",
      "actor loss: -452.133\n",
      "critic loss: 1.397\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 191:\n",
      "rewards: 23.44\n",
      "actor loss: -459.521\n",
      "critic loss: 1.702\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 192:\n",
      "rewards: 25.96\n",
      "actor loss: -463.478\n",
      "critic loss: 1.470\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 193:\n",
      "rewards: 26.60\n",
      "actor loss: -471.327\n",
      "critic loss: 1.441\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 194:\n",
      "rewards: 30.18\n",
      "actor loss: -481.106\n",
      "critic loss: 1.771\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 195:\n",
      "rewards: 25.46\n",
      "actor loss: -486.718\n",
      "critic loss: 1.667\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 196:\n",
      "rewards: 29.30\n",
      "actor loss: -493.667\n",
      "critic loss: 1.575\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 197:\n",
      "rewards: 21.82\n",
      "actor loss: -499.440\n",
      "critic loss: 1.938\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 198:\n",
      "rewards: 25.70\n",
      "actor loss: -504.825\n",
      "critic loss: 1.663\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 199:\n",
      "rewards: 26.29\n",
      "actor loss: -513.962\n",
      "critic loss: 1.353\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 200:\n",
      "rewards: 26.03\n",
      "actor loss: -519.256\n",
      "critic loss: 1.328\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 201:\n",
      "rewards: 22.18\n",
      "actor loss: -526.015\n",
      "critic loss: 2.426\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 202:\n",
      "rewards: 27.04\n",
      "actor loss: -532.934\n",
      "critic loss: 1.819\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 203:\n",
      "rewards: 25.92\n",
      "actor loss: -539.090\n",
      "critic loss: 1.487\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 204:\n",
      "rewards: 27.26\n",
      "actor loss: -542.542\n",
      "critic loss: 2.428\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 205:\n",
      "rewards: 26.64\n",
      "actor loss: -550.862\n",
      "critic loss: 2.012\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 206:\n",
      "rewards: 32.41\n",
      "actor loss: -556.792\n",
      "critic loss: 2.428\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 207:\n",
      "rewards: 31.51\n",
      "actor loss: -563.788\n",
      "critic loss: 2.585\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 208:\n",
      "rewards: 33.79\n",
      "actor loss: -567.763\n",
      "critic loss: 1.511\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 209:\n",
      "rewards: 34.13\n",
      "actor loss: -574.813\n",
      "critic loss: 1.714\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 210:\n",
      "rewards: 34.09\n",
      "actor loss: -582.357\n",
      "critic loss: 2.095\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 211:\n",
      "rewards: 31.66\n",
      "actor loss: -591.776\n",
      "critic loss: 2.013\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 212:\n",
      "rewards: 34.15\n",
      "actor loss: -596.433\n",
      "critic loss: 1.789\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 213:\n",
      "rewards: 35.05\n",
      "actor loss: -602.988\n",
      "critic loss: 2.009\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 214:\n",
      "rewards: 35.42\n",
      "actor loss: -609.851\n",
      "critic loss: 1.620\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 215:\n",
      "rewards: 31.83\n",
      "actor loss: -620.574\n",
      "critic loss: 2.366\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 216:\n",
      "rewards: 29.79\n",
      "actor loss: -624.996\n",
      "critic loss: 2.045\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 217:\n",
      "rewards: 33.55\n",
      "actor loss: -630.170\n",
      "critic loss: 2.748\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 218:\n",
      "rewards: 30.98\n",
      "actor loss: -635.638\n",
      "critic loss: 2.481\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 219:\n",
      "rewards: 28.71\n",
      "actor loss: -645.933\n",
      "critic loss: 1.876\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 220:\n",
      "rewards: 30.78\n",
      "actor loss: -649.971\n",
      "critic loss: 1.735\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 221:\n",
      "rewards: 29.59\n",
      "actor loss: -651.879\n",
      "critic loss: 2.863\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 222:\n",
      "rewards: 30.44\n",
      "actor loss: -657.681\n",
      "critic loss: 2.207\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 223:\n",
      "rewards: 31.07\n",
      "actor loss: -666.878\n",
      "critic loss: 2.241\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 224:\n",
      "rewards: 33.63\n",
      "actor loss: -670.829\n",
      "critic loss: 2.007\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 225:\n",
      "rewards: 37.04\n",
      "actor loss: -678.406\n",
      "critic loss: 2.093\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 226:\n",
      "rewards: 37.22\n",
      "actor loss: -687.099\n",
      "critic loss: 1.974\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 227:\n",
      "rewards: 37.71\n",
      "actor loss: -696.833\n",
      "critic loss: 1.594\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 228:\n",
      "rewards: 38.29\n",
      "actor loss: -699.529\n",
      "critic loss: 1.810\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 229:\n",
      "rewards: 37.04\n",
      "actor loss: -706.492\n",
      "critic loss: 2.004\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 230:\n",
      "rewards: 35.19\n",
      "actor loss: -713.116\n",
      "critic loss: 1.746\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 231:\n",
      "rewards: 35.30\n",
      "actor loss: -722.902\n",
      "critic loss: 2.527\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 232:\n",
      "rewards: 35.67\n",
      "actor loss: -725.905\n",
      "critic loss: 1.751\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 233:\n",
      "rewards: 33.07\n",
      "actor loss: -730.571\n",
      "critic loss: 3.272\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 234:\n",
      "rewards: 35.52\n",
      "actor loss: -735.394\n",
      "critic loss: 1.529\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 235:\n",
      "rewards: 35.54\n",
      "actor loss: -743.279\n",
      "critic loss: 2.983\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 236:\n",
      "rewards: 36.30\n",
      "actor loss: -745.790\n",
      "critic loss: 2.485\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 237:\n",
      "rewards: 34.77\n",
      "actor loss: -751.061\n",
      "critic loss: 2.176\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 238:\n",
      "rewards: 32.79\n",
      "actor loss: -754.162\n",
      "critic loss: 3.045\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 239:\n",
      "rewards: 32.02\n",
      "actor loss: -761.421\n",
      "critic loss: 3.173\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 240:\n",
      "rewards: 29.43\n",
      "actor loss: -763.153\n",
      "critic loss: 3.570\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 241:\n",
      "rewards: 30.39\n",
      "actor loss: -766.378\n",
      "critic loss: 3.678\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 242:\n",
      "rewards: 33.11\n",
      "actor loss: -771.451\n",
      "critic loss: 2.286\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 243:\n",
      "rewards: 35.42\n",
      "actor loss: -779.287\n",
      "critic loss: 2.498\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 244:\n",
      "rewards: 31.07\n",
      "actor loss: -779.872\n",
      "critic loss: 2.736\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 245:\n",
      "rewards: 34.85\n",
      "actor loss: -784.896\n",
      "critic loss: 3.239\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 246:\n",
      "rewards: 35.33\n",
      "actor loss: -789.970\n",
      "critic loss: 3.981\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 247:\n",
      "rewards: 35.71\n",
      "actor loss: -799.374\n",
      "critic loss: 2.541\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 248:\n",
      "rewards: 34.61\n",
      "actor loss: -801.717\n",
      "critic loss: 3.493\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 249:\n",
      "rewards: 34.22\n",
      "actor loss: -806.088\n",
      "critic loss: 2.317\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 250:\n",
      "rewards: 34.89\n",
      "actor loss: -809.894\n",
      "critic loss: 3.255\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 251:\n",
      "rewards: 31.81\n",
      "actor loss: -818.243\n",
      "critic loss: 3.001\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 252:\n",
      "rewards: 33.25\n",
      "actor loss: -817.649\n",
      "critic loss: 3.786\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 253:\n",
      "rewards: 31.73\n",
      "actor loss: -820.118\n",
      "critic loss: 4.244\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 254:\n",
      "rewards: 35.58\n",
      "actor loss: -823.246\n",
      "critic loss: 4.459\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 255:\n",
      "rewards: 33.13\n",
      "actor loss: -829.837\n",
      "critic loss: 2.846\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 256:\n",
      "rewards: 33.39\n",
      "actor loss: -830.666\n",
      "critic loss: 3.916\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 257:\n",
      "rewards: 31.13\n",
      "actor loss: -835.980\n",
      "critic loss: 4.248\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 258:\n",
      "rewards: 34.94\n",
      "actor loss: -840.257\n",
      "critic loss: 1.665\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 259:\n",
      "rewards: 36.74\n",
      "actor loss: -848.487\n",
      "critic loss: 3.635\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 260:\n",
      "rewards: 32.15\n",
      "actor loss: -848.323\n",
      "critic loss: 3.822\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 261:\n",
      "rewards: 33.85\n",
      "actor loss: -852.562\n",
      "critic loss: 2.672\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 262:\n",
      "rewards: 35.69\n",
      "actor loss: -858.501\n",
      "critic loss: 4.051\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 263:\n",
      "rewards: 37.32\n",
      "actor loss: -867.842\n",
      "critic loss: 3.146\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 264:\n",
      "rewards: 37.26\n",
      "actor loss: -869.956\n",
      "critic loss: 4.347\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "episode 265:\n",
      "rewards: 36.75\n",
      "actor loss: -875.957\n",
      "critic loss: 3.551\n",
      "noise factor: 0.0001\n",
      "buffer size: 500000\n",
      "\n",
      "SOLVED ENV AFTER 265 EPISODES"
     ]
    }
   ],
   "source": [
    "for episode in range(args['episodes']):\n",
    "\n",
    "    # episodic stats to keep track of\n",
    "    stats = {\n",
    "        'rewards': 0.,\n",
    "        'actor_loss': 0.,\n",
    "        'critic_loss': 0.,\n",
    "        'loss': 0.\n",
    "    }\n",
    "    # store for single step experience tuple\n",
    "    exp_cache = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "        actor.eval()\n",
    "        exp_cache.append(T.Tensor(state))\n",
    "\n",
    "        # begin with explorations steps and sample from uniform distribution\n",
    "        if step < args['exploration_steps']:\n",
    "            action = np.random.uniform(-1, 1, size=(20, args['action_space']))\n",
    "        else:\n",
    "            action = actor(state)\n",
    "            action = action.squeeze().detach().cpu().numpy()\n",
    "            # add noise to network actions\n",
    "            noise = np.random.randn(args['action_space']) * max(args['noise_factor'], args['noise_minimum'])\n",
    "            action = np.clip(action + noise, -1., 1.)\n",
    "\n",
    "        exp_cache.append(T.Tensor(action))\n",
    "        # take step in the environment\n",
    "        next_state, reward, done_flags, _ = env.step(action)\n",
    "\n",
    "        stats['rewards'] += (sum(reward) / 20)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # store transitions\n",
    "        exp_cache.append(T.Tensor(reward).unsqueeze(1))\n",
    "        exp_cache.append(T.Tensor(done_flags).unsqueeze(1))\n",
    "        exp_cache.append(T.Tensor(next_state))\n",
    "        exp.add(*exp_cache)\n",
    "        exp_cache.clear()\n",
    "\n",
    "        if np.any(done_flags):\n",
    "            done = True\n",
    "\n",
    "        state = next_state.copy()\n",
    "\n",
    "        # only train the network every n steps AND when threshold is reached\n",
    "        if (step % args['train_every_n'] == 0) and exp.threshold:\n",
    "            # sample from experience buffer\n",
    "            exp_states, exp_actions, exp_rewards , exp_dones, exp_next_states = exp.draw()\n",
    "            # train the critic, compute the state-action values\n",
    "            q_vals = critic(exp_states, exp_actions)\n",
    "            next_q_vals = critic_target(exp_next_states, actor_target(exp_next_states))\n",
    "            next_state_v = exp_rewards.squeeze() + (args['gamma'] * next_q_vals.squeeze().detach() * (1 - exp_dones.squeeze()))\n",
    "            critic_loss = F.mse_loss(q_vals.squeeze(), next_state_v)\n",
    "            # minimize critic_loss\n",
    "            critic.optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            clip_grad_norm_(critic.parameters(), args['clip_grad'])\n",
    "            critic.optimizer.step()\n",
    "            # train the actor network by minimizing the negative state-action values\n",
    "            actions = actor(exp_states)\n",
    "            actor_loss = -critic(exp_states, exp_actions).mean()\n",
    "            actor.optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            clip_grad_norm_(actor.parameters(), args['clip_grad'])\n",
    "            actor.optimizer.step()\n",
    "\n",
    "            # update the stats\n",
    "            stats['actor_loss'] += actor_loss\n",
    "            stats['critic_loss'] += critic_loss\n",
    "            stats['loss'] += (actor_loss + critic_loss)\n",
    "            # update the noise factor with decay\n",
    "            args['noise_factor'] *= args['noise_decay']\n",
    "        # do a soft update of the target networks every n steps with value tau\n",
    "        if step % args['model_update_every_n'] == 0:\n",
    "\n",
    "            for target_param, local_param in zip(actor_target.parameters(), actor.parameters()):\n",
    "                target_param.data.copy_(args['tau'] * local_param.data + (1.0 - args['tau']) * target_param.data)\n",
    "\n",
    "            for target_param, local_param in zip(critic_target.parameters(), critic.parameters()):\n",
    "                target_param.data.copy_(args['tau'] * local_param.data + (1.0 - args['tau']) * target_param.data)\n",
    "\n",
    "    # append the episode rewards\n",
    "    mean_rewards.append(stats['rewards'])\n",
    "\n",
    "    print(f'episode {episode}:')\n",
    "    print(f'rewards: {stats[\"rewards\"]:.2f}')\n",
    "    print(f'actor loss: {stats[\"actor_loss\"]:.3f}')\n",
    "    print(f'critic loss: {stats[\"critic_loss\"]:.3f}')\n",
    "    print(f'noise factor: {max(args[\"noise_factor\"], args[\"noise_minimum\"]):.4f}')\n",
    "    print(f'buffer size: {len(exp)}\\n')\n",
    "\n",
    "\n",
    "\n",
    "    # save models every 100 episodes\n",
    "    if episode % 50 == 0:\n",
    "        T.save(actor.state_dict(), f'actor_eps_{episode}_rew_{stats[\"rewards\"]:.2f}.h5')\n",
    "        T.save(critic.state_dict(), f'critic_eps_{episode}_rew_{stats[\"rewards\"]:.2f}.h5')\n",
    "    # env is considered solved after mean rewards of +30, save models\n",
    "    if np.mean(np.array(mean_rewards[-100:])) > 30:\n",
    "        print(f'SOLVED ENV AFTER {episode} EPISODES')\n",
    "        T.save(actor.state_dict(), f'solved_actor_eps_{episode}_rew_{stats[\"rewards\"]:.2f}.h5')\n",
    "        T.save(critic.state_dict(), f'solved_critic_eps_{episode}_rew_{stats[\"rewards\"]:.2f}.h5')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards: 37.91 after 1001 steps\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "#load actor model\n",
    "\n",
    "actor = T.load('solved_actor_eps_265_rew_36.75')\n",
    "state = env.reset()\n",
    "rewards = []\n",
    "steps = 0\n",
    "while True:\n",
    "    actor.eval()\n",
    "    action = actor(state)\n",
    "    action = action.squeeze().detach().cpu().numpy()\n",
    "    # add noise to network actions\n",
    "    noise = np.random.randn(args['action_space']) * args['noise_minimum']\n",
    "    action = np.clip(action+noise, -1., 1.)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rewards.append((sum(reward) / 20))\n",
    "    steps += 1\n",
    "    state = next_state.copy()\n",
    "    if np.any(done):\n",
    "        break\n",
    "print(f'rewards: {sum(rewards):.2f} after {steps} steps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
